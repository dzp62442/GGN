# @package _global_

defaults:
  - override /dataset: omniscene
  - override /model/encoder: costvolume
  - override /model/decoder: splatting_cuda
  - override /loss: [mse, lpips]

wandb:
  name: omniscene_112x200
  tags: [omniscene, 112x200]

data_loader:
  train:
    batch_size: 1
  val:
    batch_size: 1
  test:
    batch_size: 1

trainer:
  max_steps: 100_001
  val_check_interval: 0.01

loss:
  lpips:
    apply_after_step: 0
    weight: 0.05

dataset:
  image_shape: [112, 200]
  roots: [datasets/omniscene]
  near: 0.5
  far: 100.0
  baseline_scale_bounds: false
  make_baseline_1: false
  train_times_per_scene: 1
  highres: false

test:
  eval_time_skip_steps: 5
  compute_scores: true
